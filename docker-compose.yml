services:
  backend:
    container_name: aatmun-api
    image: aatmun-api:latest
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    depends_on:
      - ollama
    volumes:
      - ./app:/code/app
      - ./static:/code/static
    expose:
      - "8000"
    ports:
      - "8000:8000"
    restart: unless-stopped
    networks:
      - aatmun

  ollama:
    container_name: ollama
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    volumes:
      - ./data/ollama:/root/.ollama
      - ./static/scripts/entrypoint.sh:/entrypoint.sh
    tty: true
    restart: unless-stopped
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0
    networks:
      - aatmun
    # Uncomment if you have gpu
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all 
    #           capabilities: [gpu]

  frontend:
    container_name: aatmun-frontend
    image: aatmun-frontend:latest
    build:
      context: ./frontend
      dockerfile: Dockerfile
    env_file:
      - .env
    # volumes:
    #   - ./frontend:/app
    ports:
      - "3000:3000"
    restart: unless-stopped
    depends_on:
      - backend
    networks:
      - aatmun

networks:
  aatmun:
    name: aatmun
    external: false